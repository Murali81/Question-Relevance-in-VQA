{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import glob\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All the files required for VQG captioning are stored inside data_preprocessing for creating VQG_text folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "directory = 'data_preprocessing/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data_preprocessing/org_vqg_src folder \n",
    "    \n",
    "   -->    flickr_train.pickle\n",
    "   \n",
    "   -->    flickr_test.pickle\n",
    "   \n",
    "   -->    coco_train.pickle\n",
    "   \n",
    "   -->    coco_test.pickle\n",
    "   \n",
    "   -->    bing_train.pickle\n",
    "   \n",
    "This pickle files is a dataset, that is list of ['img_id','img_link','q1---q2--q3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "org_vqg = 'org_vqg_src/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(directory):\n",
    "    os.mkdir(directory)\n",
    "    print(\"You need to STORE your pickle version of csv files in data_preprocessing/org_vqg_src/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(directory+org_vqg):\n",
    "    os.mkdir(directory+org_vqg)\n",
    "    print(\"You need to STORE your pickle version of csv files in data_preprocessing/org_vqg_src/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle_files =  glob.glob(directory+org_vqg+\"*.pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### list_of_imqs = \n",
    " [ \n",
    " \n",
    "    ['image_id', ['q1','q2','q3'] ],\n",
    "    ['image_id',['q1','q2','q3'] ] \n",
    "    \n",
    " ]\n",
    "\n",
    "For every pickle file, \n",
    "\n",
    "    1.open list\n",
    "    2.filter questions ('q1---q2---q3') to ['q1','q2','q3']\n",
    "    3.Append 'img_id' , ['q1','q2','q3'] to list_of_imqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_of_imqs=[]\n",
    "for pic_fil in pickle_files:\n",
    "    \n",
    "    with open(pic_fil,\"rb\") as fh:\n",
    "        \n",
    "        list_of_imlinkqs = pickle.load(fh)  #[['img_id','img_link','q1---q2---q3']]\n",
    "        \n",
    "        \n",
    "        \n",
    "        for instance in list_of_imlinkqs:\n",
    "            \n",
    "            questions = instance[2].split(\"---\")     # Getting multiple questions\n",
    "            questions= [ques[:-1] for ques in questions]  # Removing \"?\" from every question to remove bias\n",
    "            img_id = instance[0]\n",
    "            list_of_imqs.append([str(img_id),questions])\n",
    "            \n",
    "        \n",
    "            \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## img_question_dict =\n",
    "\n",
    "    key     =   val\n",
    "    img_id  =   ['q1','q2','q3']\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_question_dict=dict()\n",
    "for img_id,questions in list_of_imqs:\n",
    "    img_question_dict[str(img_id)] = questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(directory+\"img2questions_dict.pickle\",\"wb\") as fh:\n",
    "    pickle.dump(img_question_dict,fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_directory='VQg_text/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(text_directory):\n",
    "    os.mkdir(text_directory)\n",
    "    print(\"For storing info on img, questions and train,test splits\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(directory+\"img2questions_dict.pickle\",\"rb\") as fh:\n",
    "    img_question_dict=pickle.load(fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_directory = 'VQg_Dataset/VQG_Dataset/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### img_files = \n",
    "\n",
    "[\n",
    "\n",
    "'VQg_Dataset/VQG_Dataset\\\\00051bba-46a4-4aac-876d5c18bb32fc74.jpg',\n",
    "\n",
    " 'VQg_Dataset/VQG_Dataset\\\\0043f1ba-1028-4d37-9a7e4f2204978749.jpg',\n",
    " \n",
    " 'VQg_Dataset/VQG_Dataset\\\\00472679-97c5-449a-9ece4d55370344f4.jpg'\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "img_files = glob.glob(img_directory+\"*.*\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### img_file_names = \n",
    "\n",
    "[\n",
    "\n",
    "'00051bba-46a4-4aac-876d5c18bb32fc74.jpg',\n",
    "\n",
    " '0043f1ba-1028-4d37-9a7e4f2204978749.jpg',\n",
    " \n",
    " '00472679-97c5-449a-9ece4d55370344f4.jpg'\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "img_file_names = [os.path.basename(x) for x in img_files] ## removing the path part, keeping only the filenames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### img_id_file_map = dict()\n",
    "\n",
    "    key      =     val\n",
    "\n",
    "    img_id   =   corresponding image file name\n",
    "    \n",
    "    img_id   =   img_id.jpg\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_id_file_map = dict()\n",
    "\n",
    "for img_fil in img_file_names:\n",
    "    img_id_file_map[str((img_fil.split(\".\"))[0] )] = img_fil \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VQG.token.txt file has\n",
    "\n",
    "    img1_.jpg#0 \\t question1\n",
    "    \n",
    "    img1_.jpg#1 \\t question2\n",
    "    \n",
    "    img2_.jpg#0 \\t question1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "text = ''\n",
    "\n",
    "for img,questions in img_question_dict.items():\n",
    "    \n",
    "    for indx,question in enumerate(questions):\n",
    "        \n",
    "        try:\n",
    "            img_address = img_id_file_map[img]\n",
    "            text += img_address +\"#\"+str(indx)+\"\\t\"+question+\"\\n\"\n",
    "            \n",
    "        except:\n",
    "            \n",
    "            pass\n",
    "\n",
    "text =text[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_capt_file = 'VQG.token.txt'\n",
    "\n",
    "with open(text_directory+img_capt_file,'w') as fh:\n",
    "    fh.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_size = len(img_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VQG.trainImages.txt has\n",
    "\n",
    "    img1.jpg\n",
    "    \n",
    "    img2.jpg\n",
    "    \n",
    "    .. All training instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_file='VQG.trainImages.txt'\n",
    "test_file='VQG.testImages.txt'\n",
    "val_file='VQG.devImages.txt'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_size = int( len(img_files) * 0.8)\n",
    "test_size = int(len(img_files) * 0.1)\n",
    "val_size = int(len(img_files) * 0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "img_filnames_arr = np.array(img_file_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from random import shuffle\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(9)\n",
    "\n",
    "np.random.shuffle(img_filnames_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = ''\n",
    "\n",
    "for img in img_filnames_arr[:train_size]:\n",
    "    text+=img+\"\\n\"\n",
    "\n",
    "text = text [:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(text_directory+train_file,'w') as fh:\n",
    "    fh.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text = ''\n",
    "\n",
    "for img in img_filnames_arr[train_size:train_size + val_size]:\n",
    "    text+=img+\"\\n\"\n",
    "\n",
    "text = text [:-1]\n",
    "\n",
    "with open(text_directory+val_file,'w') as fh:\n",
    "    fh.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text = ''\n",
    "\n",
    "starting_idx = train_size + val_size\n",
    "\n",
    "for img in img_filnames_arr[starting_idx:starting_idx + test_size]:\n",
    "    text+=img+\"\\n\"\n",
    "\n",
    "text = text [:-1]\n",
    "\n",
    "with open(text_directory+test_file,'w') as fh:\n",
    "    fh.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
